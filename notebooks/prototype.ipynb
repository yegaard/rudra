{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b77a2f-3ba2-41bb-981e-8aa2328779a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b4f34-468b-4289-8479-d174a8c93da4",
   "metadata": {},
   "source": [
    "#### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e798af4-4134-44b7-93b2-1923115da411",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarker_path = '../models/pose_landmarker_heavy.task'\n",
    "\n",
    "with open('../models/downdog_model.pkl', 'rb') as file:\n",
    "    downdog_model = pickle.load(file)\n",
    "\n",
    "with open('../models/updog_model.pkl', 'rb') as file:\n",
    "    updog_model = pickle.load(file)\n",
    "\n",
    "with open('../models/cobra_model.pkl', 'rb') as file:\n",
    "    cobra_model = pickle.load(file)\n",
    "\n",
    "with open('../models/asana_model.pkl', 'rb') as file:\n",
    "    asana_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7034922-dcad-4ffd-ac8f-516480d06e9f",
   "metadata": {},
   "source": [
    "#### Create the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca4bbbe-afba-4c66-b8b7-7f5ff682397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "PoseLandmarkerResult = mp.tasks.vision.PoseLandmarkerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=landmarker_path),\n",
    "    output_segmentation_masks=True,\n",
    "    running_mode=VisionRunningMode.VIDEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0063e-b966-42cb-af66-d2a7e1f5c593",
   "metadata": {},
   "source": [
    "#### Function to draw landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c792cbd1-f085-40d1-8a3e-8bb419adb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306f879-72a7-43d7-a029-2719efdc4f4a",
   "metadata": {},
   "source": [
    "#### Get and process webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "779df237-43ae-4fd7-acb4-037065da5be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718020734.818657  260957 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1718020734.821076  262890 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.1.1-arch1.1), renderer: Mesa Intel(R) HD Graphics 620 (KBL GT2)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../data/vids/1b.mp4')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "prev_timestamp = 0\n",
    "\n",
    "# Initiate pose model\n",
    "with PoseLandmarker.create_from_options(options) as detector:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # optimization\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "\n",
    "        frame_timestamp_ms = prev_timestamp + 200\n",
    "        prev_timestamp = frame_timestamp_ms\n",
    "        \n",
    "        # Make detections\n",
    "        results = detector.detect_for_video(mp_image, frame_timestamp_ms)\n",
    "\n",
    "        # Recolor image back\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "       \n",
    "        # Draw pose landmarks\n",
    "        annotated_image = draw_landmarks_on_image(image, results)\n",
    "        annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            data = []\n",
    "            for pose_landmarks in results.pose_landmarks:\n",
    "                landmarks_data = []\n",
    "                for pose_landmark in pose_landmarks:\n",
    "                    landmarks_data.append({\n",
    "                        'x': pose_landmark.x,\n",
    "                        'y': pose_landmark.y,\n",
    "                        'z': pose_landmark.z,\n",
    "                        'visibility': pose_landmark.visibility,\n",
    "                        'presence': pose_landmark.presence\n",
    "                    })\n",
    "            data.extend(landmarks_data)\n",
    "            \n",
    "            pose = pd.DataFrame(data).drop(columns=['visibility', 'presence']).values.flatten()\n",
    "            \n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([pose])\n",
    "\n",
    "            asana = asana_model.predict(X)\n",
    "            asana_proba = asana_model.predict_proba(X)\n",
    "            confidence_threshold = 0.75\n",
    "\n",
    "            output = ''\n",
    "            correctness = ''\n",
    "            if np.max(asana_proba) >= confidence_threshold:\n",
    "                if asana[0] == 'downdog':\n",
    "                    correctness = downdog_model.predict(X)\n",
    "                elif asana[0] == 'updog':\n",
    "                    correctness == updog_model.predict(X)\n",
    "                elif asana[0] == 'cobra':\n",
    "                    correctness == cobra_model.predict(X)\n",
    "                output = str(asana[0]) + ': ' + str(correctness[0])\n",
    "                \n",
    "            #correctness_proba = downdog_model.predict_proba(X)\n",
    "\n",
    "            coords = tuple([100, 100])\n",
    "            cv2.putText(annotated_image, output.upper(), coords, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('',cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e90dee-186f-4d29-986c-3593cbd4579c",
   "metadata": {},
   "source": [
    "##### In case the window was not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dce62935-836d-4cbf-a36d-be97b38dcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
